# Copyright (c) OpenMMLab. All rights reserved.
import torch
from mmcv.runner import BaseModule

from mmdet3d.core.bbox import (CameraInstance3DBoxes, DepthInstance3DBoxes,
                               LiDARInstance3DBoxes)
from mmdet.models.builder import ROI_EXTRACTORS


@ROI_EXTRACTORS.register_module()
class BEVFeatureExtractor(BaseModule):
    """Extract features from the BEV featrue map generated by the one-stage
    backbone.

    Args:
        pc_start (list[float]): Start point of point cloud's range
        voxel_size (list[float]): Voxel size of first 2 dimensions
        downsample_stride (int): Downsample factor of the backbone feature map
    """

    def __init__(
        self,
        pc_start,
        voxel_size,
        downsample_stride,
    ):
        super(BEVFeatureExtractor, self).__init__()
        self.pc_start = pc_start
        self.voxel_size = voxel_size
        self.downsample_stride = downsample_stride

    def forward(self, bev_feature, rois):
        """Forward function to BEV feature extractor.

        Args:
            bev_feature (list[torch.Tensor]): Multi-level feature maps. The
                 shape of each feature map is [B, C_i, H_i, W_i]
            rois (list[list[bboxes, ...]]): Decoded bbox, scores and labels
                The out list indicates the rois in a batch.
                - bboxes (:obj:`BaseInstance3DBoxes`): Prediction bboxes

        Returns:
            list[torch.Tensor]: roi features with shape of [N, 5*C]
        """

        # NOTE: ONLY surpport the latest output of BEV feature maps now
        bev_feature = bev_feature[-1]

        roi_features = []
        batch_size = len(bev_feature)
        num_points = 5
        for i in range(batch_size):
            bboxes = rois[i][0]
            num_boxes = len(bboxes)
            feature_points = self.get_feature_points(bboxes)  # [5*num_box, 2]

            xs = (feature_points[..., 0] - self.pc_start[0]
                  ) / self.voxel_size[0] / self.downsample_stride
            ys = (feature_points[..., 1] - self.pc_start[1]
                  ) / self.voxel_size[1] / self.downsample_stride

            features = self.bilinear_interpolate(bev_feature[i], xs,
                                                 ys)  # [5*num_box, C]

            roi_feature = torch.cat([
                features[i * num_boxes:(i + 1) * num_boxes]
                for i in range(num_points)
            ],
                                    dim=1)  # [num_box, 5*C]
            roi_features.append(roi_feature)

        return roi_features

    @staticmethod
    def get_feature_points(bbox):
        """Get feature points of bbox.

        Args:
            bbox (:obj:`BaseInstance3DBoxes`): Prediction bboxes

        Returns:
            torch.Tensor: The location of feature points. [5*num_box, 3]
        """

        # get corners
        if isinstance(bbox, LiDARInstance3DBoxes):
            front_left = bbox.corners[:, 4, :2].squeeze(1)  # [num_box, 2]
            back_left = bbox.corners[:, 0, :2].squeeze(1)
            front_right = bbox.corners[:, 7, :2].squeeze(1)
            back_right = bbox.corners[:, 3, :2].squeeze(1)
        elif isinstance(bbox, CameraInstance3DBoxes):
            raise NotImplementedError
        elif isinstance(bbox, DepthInstance3DBoxes):
            raise NotImplementedError
        else:
            raise NotImplementedError

        # get feature points
        center = bbox.bottom_center[:, :2]  # [num_box, 2]
        front = (front_left + front_right) / 2.0
        back = (back_left + back_right) / 2.0
        left = (front_left + back_left) / 2.0
        right = (front_right + back_right) / 2.0
        points = torch.cat([center, front, back, left, right],
                           dim=0)  # [5*num_box, 2]

        return points

    @staticmethod
    def bilinear_interpolate(bev_feature, x, y):
        """Sample features in bev by bilinear interpolation.

        Args:
            bev_feature (torch.Tensor): Features in BEV with shape of
                [C, H, W].
            x (torch.Tensor): The location of points with shape of [N]
            y (torch.Tensor): The location of points with shape of [N]

        Returns:
            torch.Tensor: Sampled features with shape of [N, C]
        """
        bev_feature = bev_feature.permute(
            1, 2, 0).contiguous()  # [C, H, W] -> [H, W, C]

        x0 = torch.floor(x).long()
        x1 = x0 + 1

        y0 = torch.floor(y).long()
        y1 = y0 + 1

        x0 = torch.clamp(x0, 0, bev_feature.shape[1] - 1)
        x1 = torch.clamp(x1, 0, bev_feature.shape[1] - 1)
        y0 = torch.clamp(y0, 0, bev_feature.shape[0] - 1)
        y1 = torch.clamp(y1, 0, bev_feature.shape[0] - 1)

        Ia = bev_feature[y0, x0]
        Ib = bev_feature[y1, x0]
        Ic = bev_feature[y0, x1]
        Id = bev_feature[y1, x1]

        wa = (x1.type_as(x) - x) * (y1.type_as(y) - y)
        wb = (x1.type_as(x) - x) * (y - y0.type_as(y))
        wc = (x - x0.type_as(x)) * (y1.type_as(y) - y)
        wd = (x - x0.type_as(x)) * (y - y0.type_as(y))
        ans = torch.t(
            (torch.t(Ia) * wa)) + torch.t(torch.t(Ib) * wb) + torch.t(
                torch.t(Ic) * wc) + torch.t(torch.t(Id) * wd)
        return ans
